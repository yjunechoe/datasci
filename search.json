[
  {
    "objectID": "labs/1-getting-started-with-r-lab.html",
    "href": "labs/1-getting-started-with-r-lab.html",
    "title": "Lab 1: Getting started with R",
    "section": "",
    "text": "To learn to program in R (or any language), you can read about how to do it, and watch someone else do it; but the only way to really learn is to do it yourself. Create some data structures, try some stuff, and see what happens! Here are some practice quiz questions to guide your learning. We will go over the solutions to these in lab."
  },
  {
    "objectID": "labs/1-getting-started-with-r-lab.html#r-basics",
    "href": "labs/1-getting-started-with-r-lab.html#r-basics",
    "title": "Lab 1: Getting started with R",
    "section": "R Basics",
    "text": "R Basics\n\nWhich of the following are expressions? Choose all that apply.\n\n10\n5 + 10\nx &lt;- 5 + 10\nx &lt;- y + 10\nmean(x)\n\nWhich of the following are valid variable names in R?\n\nchildAge\nresponse_time\n1stPlaceWinner\n2fast2furious\nfast&furious\n\nSuppose we run the following code block. What will ls() return?\nx &lt;- mean(1, 3, 5)\ny &lt;- median(1, 3, 5)\nSuppose we run library(tidyverse) in Google Colab and receive the following error message? How do we solve this problem?\n\nNameError: name 'library' is not defined"
  },
  {
    "objectID": "labs/1-getting-started-with-r-lab.html#vectors",
    "href": "labs/1-getting-started-with-r-lab.html#vectors",
    "title": "Lab 1: Getting started with R",
    "section": "Vectors",
    "text": "Vectors\n\nThe expression attributes(x) returns the following result. What will typeof(x) return?\n\n$dim= 2 . 2\n\nSuppose we run the following code block. What will typeof(x) return?\nx &lt;- c()\nExplain in one sentence the difference between an atomic vector and a list.\nSuppose we run the following code block. What will typeof(x) return? What about length(x)? Explain why.\nx &lt;- data.frame(x=c(1,2,3), y=c(\"a\",\"b\",\"c\"))\nSuppose we run the following code. What will y return? What about typeof(y)?\nx &lt;- c(2,4,6)\ny &lt;- x * 2"
  },
  {
    "objectID": "labs/1-getting-started-with-r-lab.html#subsetting",
    "href": "labs/1-getting-started-with-r-lab.html#subsetting",
    "title": "Lab 1: Getting started with R",
    "section": "Subsetting",
    "text": "Subsetting\n\nSuppose we run the following code. What will each of operations return (a - e)?\nx &lt;- seq(2:8, by=2)\n\nx[c(2,4)]\nx[-c(2,4)]\nx[]\nx[[2]]\nx[2]\n\nSuppose m is a matrix created with matrix(c(1,2,3,4), nrow=2, ncol=2). What will each of the following operations return?\n\nm[c(1), ]\nm[c(2), c(1, 2)]\nm[]\nm[[2]]\n\nSuppose df is a data frame created with data.frame(x=c(1,2,3), y=c(\"a\",\"b\",\"c\")). What will each of the following operations return?\n\ndf[c(1,2)]\ndf[c(1,2), c(2)]\ndf[['x']]\ndf[x]\ndf[[2]]\n\nSuppose df is a dataframe with column names ageChild, ageParent, and dateAdded. What will df$age return? Explain why."
  },
  {
    "objectID": "labs/1-getting-started-with-r-lab.html#programming-in-r",
    "href": "labs/1-getting-started-with-r-lab.html#programming-in-r",
    "title": "Lab 1: Getting started with R",
    "section": "Programming in R",
    "text": "Programming in R\n\nExplain in one sentence the difference between a for loop and a while loop?"
  },
  {
    "objectID": "labs/2-data-importing-and-viz.html",
    "href": "labs/2-data-importing-and-viz.html",
    "title": "Lab 2: Getting started with tidyverse",
    "section": "",
    "text": "Practice quiz questions.\n\nSuppose we run the following code block. What will is.data.frame(y) return?\ny &lt;- tibble(x=1:2, y=1)`\nSuppose print(x) returns the output below to answer a-c that follow.\n\n# output\n\n\nWhat will map_dbl(x, sum) return?\nWhat will x$a return?\nWhat will x[[5]] return?\n\nSuppose x[[5]] returns NULL, what will is_tibble(x) return?\nCan readr import a google sheet with the read_csv() function?"
  },
  {
    "objectID": "rbasics.html",
    "href": "rbasics.html",
    "title": "LING0700",
    "section": "",
    "text": "2 + 3\n\n5\n\n\n\nlibrary(tidyverse)\n\nERROR: Error in library(tidyverse): there is no package called 'tidyverse'"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data sci for lang & mind",
    "section": "",
    "text": "contact: katie, june, avinash, ravi\nresources: ed, canvas, gradescope, colab (r notebook)\n\n\n\n\nDay\nUnit\nTopic\nResources\n\n\n\n\n08-28\nR\nHello, world!\n\n\n\n08-31\nR\nR-basics\nlab1\n\n\n09-05\nR\nData importing\n\n\n\n09-07\nR\nData visualization\n\n\n\n09-10\nR\nProblem set 1\n\n\n\n09-12\nR\nData transformation\n\n\n\n09-14\nR\nData tidying\n\n\n\n09-19\nR\nQuiz 1\n\n\n\n09-20\nStats\nProbability distributions\n\n\n\n09-26\nStats\nSampling variability\n\n\n\n09-28\nStats\nHypothesis testing\n\n\n\n10-01\nStats\nProblem set 2\n\n\n\n10-03\nModel\nModel specification\n\n\n\n10-05\nModel\nModel fitting\n\n\n\n10-10\nModel\nQuiz 2\n\n\n\n10-12\nModel\nNo class, break\n\n\n\n10-17\nModel\nModel accuracy\n\n\n\n10-19\nModel\nModel reliability\n\n\n\n10-22\nModel\nProblem set 3\n\n\n\n10-24\nInfer\nConditions for inference\n\n\n\n10-26\nInfer\nInference on regression models\n\n\n\n10-31\nInfer\nQuiz 3\n\n\n\n11-02\nInfer\nTBD\n\n\n\n11-07\nSpecials\nFeature selection\n\n\n\n11-09\nSpecials\nCase study 1\n\n\n\n11-12\nSpecials\nProblem set 4\n\n\n\n11-14\nSpecials\nEthics\n\n\n\n11-16\nSpecials\nCase study 2\n\n\n\n11-21\nSpecials\nQuiz 4\n\n\n\n11-23\nSpecials\nNo class, break\n\n\n\n11-28\nAdvanced\nClassification\n\n\n\n11-30\nAdvanced\nCase study 3\n\n\n\n12-03\nAdvanced\nProblem set 5\n\n\n\n12-05\nAdvanced\nMultilevel models\n\n\n\n12-07\nAdvanced\nCase study 4\n\n\n\n12-10\nAdvanced\nProblem set 6"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Welcome to Data Science for Studying Language & the Mind! The Fall 2023 course information and syllabus are below. Course materials for previous semesters are archived here."
  },
  {
    "objectID": "syllabus.html#course-description",
    "href": "syllabus.html#course-description",
    "title": "Syllabus",
    "section": "Course description",
    "text": "Course description\nData Sci for Lang & Mind is an entry-level course designed to teach basic principles of statistics and data science to students with little or no background in statistics or computer science. Students will learn to identify patterns in data using visualizations and descriptive statistics; make predictions from data using machine learning and optimization; and quantify the certainty of their predictions using statistical models. This course aims to help students build a foundation of critical thinking and computational skills that will allow them to work with data in all fields related to the study of the mind (e.g. linguistics, psychology, philosophy, cognitive science, neuroscience).\nThere are no prerequisites beyond high school algebra. No prior programming or statistics experience is necessary, though you will still enjoy this course if you already have a little. Students who have taken several computer science or statistics classes should look for a more advanced course."
  },
  {
    "objectID": "syllabus.html#people",
    "href": "syllabus.html#people",
    "title": "Syllabus",
    "section": "People",
    "text": "People\n\nInstructor: Dr. Katie Schuler\nTAs: June Choe, Avinash Goss, Ravi Arya"
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nTuesdays and Thursdays at 10:15am in COHN 402."
  },
  {
    "objectID": "syllabus.html#labs",
    "href": "syllabus.html#labs",
    "title": "Syllabus",
    "section": "Labs",
    "text": "Labs\nHands-on practice, quiz prep, and problem set work guided by TAs.\n\n402: Thu at 1:45p in WILL 4 with TA\n403: Thu at 3:30p in TOWN 305 with TA\n404: Fri at 10:15a in WILL 24 with Ravi\n405: Fri at 12:00p in TOWN 307 with Avinash"
  },
  {
    "objectID": "syllabus.html#office-hours",
    "href": "syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office hours",
    "text": "Office hours\nThe linguistics department is on the 3rd floor of the C-wing at 3401 Walnut street, between Franklin’s Table and Modern Eye.\n\nKatie: Tue 12:30-1:30p in 314 ling dept\nJune: TBD in ling dept\nAvinash: TBD\nRavi: TBD"
  },
  {
    "objectID": "syllabus.html#quizzes",
    "href": "syllabus.html#quizzes",
    "title": "Syllabus",
    "section": "Quizzes",
    "text": "Quizzes\nThere are 4 quizzes, taken in class on Tuesdays. Missed quizzes cannot be made up except in cases of genuine conflict or emergency (documentation and a Course Action Notice are required). Instead, you will be invited to submit a missed quiz for half credit (50%)."
  },
  {
    "objectID": "syllabus.html#problem-sets",
    "href": "syllabus.html#problem-sets",
    "title": "Syllabus",
    "section": "Problem sets",
    "text": "Problem sets\nThere are 6 problem sets, due on Sundays to Gradescope by 11:59pm. Students may request an extension of up to 3 days. Extensions beyond this are not permitted, because delaying the release of solutions would negatively impact other students. After solutions are posted, late problem sets can be submitted for half credit (50%)."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\n\n60% problem sets (equally weighted, lowest dropped)\n40% quizzes (equally weighted)\nLetter grade minimums: 97% A+, 93% A, 90% A-, 87% B+, 84% B, 80% B-, 77% C+, 74% C, 70% C-, 67% D+, 64% D, 61% D-, else F\nAll problems will be graded according to this rubric."
  },
  {
    "objectID": "syllabus.html#collaborations",
    "href": "syllabus.html#collaborations",
    "title": "Syllabus",
    "section": "Collaborations",
    "text": "Collaborations\nCollaboration on problem sets is highly encouraged! If you collaborate, you need to write your own code/solutions, name your collaborators, and cite any outside sources you consulted (you don’t need to cite the course material)."
  },
  {
    "objectID": "syllabus.html#accomodations",
    "href": "syllabus.html#accomodations",
    "title": "Syllabus",
    "section": "Accomodations",
    "text": "Accomodations\nWe will support any accommodations arranged through Disability Services via the Weingarten Center."
  },
  {
    "objectID": "syllabus.html#extra-credit",
    "href": "syllabus.html#extra-credit",
    "title": "Syllabus",
    "section": "Extra credit",
    "text": "Extra credit\nThere is no extra credit in the course. However, students can submit any missed problem set or quiz by the end of the semester for half credit (50%). To ensure fair treatment across all students, all students will receive a 1% “bonus” to their final course grade: 92.54% will become 93.54%."
  },
  {
    "objectID": "syllabus.html#regrade-requests",
    "href": "syllabus.html#regrade-requests",
    "title": "Syllabus",
    "section": "Regrade requests",
    "text": "Regrade requests\nRegrade requests should be made in writing within one week of receiving your graded assignment. Please explain why you believe there was a grading mistake, given the posted solutions and rubric."
  },
  {
    "objectID": "syllabus.html#resources",
    "href": "syllabus.html#resources",
    "title": "Syllabus",
    "section": "Resources",
    "text": "Resources\nIn addition to the course website, we will use the following:\n\ngoogle colab (r kernel) - for computing\ncanvas - for posting grades\ngradescope - for submitting problem sets\ned discussion - for announcements and questions\n\nPlease consider using these Penn resources this semester:\n\nWeingarten Center for academic support and tutoring.\nWellness at Penn for health and wellbeing."
  },
  {
    "objectID": "lecturenotes/probability-distributions.html",
    "href": "lecturenotes/probability-distributions.html",
    "title": "Probablity distributions",
    "section": "",
    "text": "Setup code\n# ------ setup for today's lecture notes ----- # \n\n# suppress startup messages at package load\nsuppressPackageStartupMessages(library(tidyverse))\n\n# set the theme for the plots \ntheme_set(theme_classic(base_size=15))\n\n# generate 10000 y values with mean 3 and sd 0.25\ndata &lt;- tibble(\n    y=rnorm(1000, mean=3, sd=0.25)\n) \n\n\nWe begin with the simplest possible dataset: suppose we measure a single quantity y. What can we do with these data?\nWe can create a visual summary of our dataset with a histogram. A histogram plots the distribution of a set of data, which allows us to get a quick visual of the data: formally we have plotted the the frequency distribution (count) of the data, but this also gives a sense of the central tendency and variability in our dataset.\n\n\nCode\nggplot(data=data, aes(x=y)) +\n    geom_histogram(\n        binwidth = 0.25,\n        color=\"black\", fill='lightgray', alpha=0.5\n    )"
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#exploring-a-simple-dataset",
    "href": "lecturenotes/probability-distributions.html#exploring-a-simple-dataset",
    "title": "Probablity distributions",
    "section": "",
    "text": "Setup code\n# ------ setup for today's lecture notes ----- # \n\n# suppress startup messages at package load\nsuppressPackageStartupMessages(library(tidyverse))\n\n# set the theme for the plots \ntheme_set(theme_classic(base_size=15))\n\n# generate 10000 y values with mean 3 and sd 0.25\ndata &lt;- tibble(\n    y=rnorm(1000, mean=3, sd=0.25)\n) \n\n\nWe begin with the simplest possible dataset: suppose we measure a single quantity y. What can we do with these data?\nWe can create a visual summary of our dataset with a histogram. A histogram plots the distribution of a set of data, which allows us to get a quick visual of the data: formally we have plotted the the frequency distribution (count) of the data, but this also gives a sense of the central tendency and variability in our dataset.\n\n\nCode\nggplot(data=data, aes(x=y)) +\n    geom_histogram(\n        binwidth = 0.25,\n        color=\"black\", fill='lightgray', alpha=0.5\n    )"
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#descriptive-statistics",
    "href": "lecturenotes/probability-distributions.html#descriptive-statistics",
    "title": "Probablity distributions",
    "section": "2 Descriptive statistics",
    "text": "2 Descriptive statistics\nWe can summarize (or describe) a set of data with descriptive statistics. There are three types of measures:\n\ncentral tendency describes a central or typical value (mean, median, mode)\nvariability describes dispersion or spread of values (variance, standard deviation, IQR)\nfrequency distribution describes how frequently different values occur (count)\n\nR has built-in functions to handle descriptive statistics (we saw these in lecture 1):\n\ndata %&gt;%\n    summarise(\n        n = n(), \n        mean = mean(y),\n        median = median(y),\n        sd = sd(y),\n        iqr_lower = quantile(y, 0.25),\n        iqr_upper = quantile(y, 0.75)\n    ) \n\n\n\n\n\nn\nmean\nmedian\nsd\niqr_lower\niqr_upper\n\n\n\n\n1000\n2.999982\n3.00279\n0.2552595\n2.825829\n3.174198"
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#parametric-vs.-nonparametric",
    "href": "lecturenotes/probability-distributions.html#parametric-vs.-nonparametric",
    "title": "Probablity distributions",
    "section": "3 Parametric vs. nonparametric",
    "text": "3 Parametric vs. nonparametric\nSome statistics are considered paramteric because they make assumptions about the the distribution of the data (can therefore be computed theoretically from parameters):\n\nThe mean and standard deviation assume the distribution is Gaussian and can therefore be computed via the following equations\nmean \\(\\mu\\)\nsd \\(\\sigma\\)\n\nOther statstics are nonparametric because they make minimal assumptions about the distribution of the data:\n\nmedian is the 50th percentile, the value below which 50% of the data points fall.\ninter-quartile range (IQR) is the difference between the 25th and 75th percentiles (sometimes called the 50% coverage interval because 50% of the data fall in this range).\n\nNote that we can calculate any arbitrary coverage interval. The 95% coverage interval — widely used in the sciences — is the difference between the 2.5 percentile and the 97.5 percentile, including all but 5% of the data."
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#probability-distributions",
    "href": "lecturenotes/probability-distributions.html#probability-distributions",
    "title": "Probablity distributions",
    "section": "4 Probability distributions",
    "text": "4 Probability distributions\nA probability distribution (aka probability density function) is a mathematical function that describes the probability of observing the different possible values of a variable (or variables). We will focus on univariate distributions in this class — probability distributions of just one random variable — but probability distributions can also be multivariate.\n\nOne of the simplest probability distributions is the uniform distribution, where all possible values of a variable are equally likely. The probability density function for the uniform distribution is given by the following equation with two parameters (the boundaries, min and max):\n\n\\(p(x) = \\frac{1}{max-min}\\)\n\nOne of the most useful probability distributions for our purposes is the Gaussian (or Normal) distribution. The probability density function for the Gaussian distribution is given by the following equation, with the parameters \\(\\mu\\) (mean) and \\(\\sigma\\) (standard deviation):\n\n\\(p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left(-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^{2}\\right)\\)\nThe Gaussian distribution assumes that the distribution of a set of data takes a certain form (is unimodal, symmetric, etc).\nWhen values are sampled from a Gaussian distribution, 68% of the values will be within one standard deviation from the mean and 95% within two standard deviations from the mean.\nWhen computing the mean and standard deviation of a set of data, we are fitting a Gaussian distribution to the data."
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#probability-distributions-with-r",
    "href": "lecturenotes/probability-distributions.html#probability-distributions-with-r",
    "title": "Probablity distributions",
    "section": "5 Probability distributions with R",
    "text": "5 Probability distributions with R\nThe probability distributions we’ve discussed so far are considered “parametric” because they are given by one or more parameters. When we use R’s functions to generate values from these distributions, we provide these parameters as arguments. Base R has four functions we will use to generate values associated with a probability distribution. - dnorm(mean=5, sd=1) returns the height of the probability density function at the given values - pnorm(5, mean=5, sd=1) returns the cumulative density function (the probability that a random number from the distribution will be less than the given values) - qnorm(0.8, mean=5, sd=1) returns the value whose cumulative distribution matches the probability (inverse of p) - rnorm(1000, mean=5, sd=1) returns n random numbers generated from the distribution\nTo use another distribution, change the function’s suffix to the name of the distribution and the parameters to those that define the distribution. For example, to generate n random numbers from a uniform distribution with a min of 1 and a max of 5, run runif(n, min=0, max=1)."
  },
  {
    "objectID": "lecturenotes/probability-distributions.html#nonparametric-probability-distributions",
    "href": "lecturenotes/probability-distributions.html#nonparametric-probability-distributions",
    "title": "Probablity distributions",
    "section": "6 Nonparametric probability distributions",
    "text": "6 Nonparametric probability distributions\nWhat if the data does not meet the assumptions of the Gaussian distribution? One option is to choose another parametric probability distribution (run help(Distributions) for a full list of available distributions). Another is to use a nonparametric approach, where the probability distribution is not determined by parameters but is instead determined by the data. - A histogram is actually a simple, nonparametric estimate of a probability distribution. To estimate the probability distribution that generated a set of data from a histogram, we modify the scale of the y-axis so that the total area of the bars is equal to 1. - Kernel density estimation (KDE) is another nonparametric method to estimate a probability distribution. KDE is like a smooth histogram, accomplished by placeing a kernel — a tiny Gaussian distribution — at each observed data point and summing across kernels. We can accomplish this in ggplot with the geom_density() geom.\n\nFurther reading and references\n\nAppendix A: Statistical Background in Modern Dive\nCh 11: Modeling Randomness in Statistical Modeling\n\nhttps://r4ds.hadley.nz/data-visualize#visualizing-distributions"
  },
  {
    "objectID": "lecturenotes/r/hello-world.html#why-r",
    "href": "lecturenotes/r/hello-world.html#why-r",
    "title": "Hello, World!",
    "section": "Why R?",
    "text": "Why R?\nWith many programming languages available for data science (e.g. R, Python, Julia, MATLAB), why use R?\n\nBuilt for stats, specifically\nMakes nice visualizations\nLots of people are doing it, especially in academia\nEasier for beginners to understand\nFree and open source (though so are Python and Julia, MATLAB costs $)\n\nIf you are interested, here is a math professor’s take on the differences between Python, Julia, and MATLAB. Note that although they’re optimized for different things, they’re all great and the technical skills and conceptual knowledge you gain in this course easily transfers to other languages."
  },
  {
    "objectID": "lecturenotes/r/hello-world.html#google-colab",
    "href": "lecturenotes/r/hello-world.html#google-colab",
    "title": "Hello, World!",
    "section": "Google Colab",
    "text": "Google Colab\nThere are many ways to program with R. Some popular options include:\n\nR Studio\nJupyter\nVS Code\nand even simply the command line/terminal\n\nGoogle Colab is a cloud-based Jupyter notebook that allows you to write, execute, and share code like a google doc. We use Google Colab because it’s simple and accessible to everyone. You can start programming right away, no setup required! Google Colab officially supports Python, but secretly supports R (and Julia, too!)\nNew R notebook:\n\ncolab (r kernel) - use this link to start a new R notebook\nFile &gt; New notebook error, Python! name 'x' is not defined\n\nCell types:\n\n+ Code - write and execute code\n+ Text - write text blocks in markdown\n\nLeft sidebar:\n\nTable of contents - outline from text headings\nFind and replace - find and/or replace\nFiles - upload files to cloud session\n\nFrequently used menu options:\n\nFile &gt; Locate in Drive - where in your Google Drive?\nFile &gt; Save - saves\nFile &gt; Revision history - history of changes you made\nFile &gt; Download &gt; Download .ipynb - used to submit assignments!\nFile &gt; Print - prints\nRuntime &gt; Run all - run all cells\nRuntime &gt; Run before - run all cells before current active cell\nRuntime &gt; Restart and run all - restart runtime, then run all\n\nFrequently used keyboard shortcuts:\n\nCmd/Ctrl+S - save\nCmd/Ctrl+Enter - run focused cell\nCmd/Ctrl+Shift+A - select all cells\nCmd/Ctrl+/ - comment/uncomment selection\nCmd/Ctrl+] - increase indent\nCmd/Ctrl+[ - decrease indent"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html",
    "href": "lecturenotes/r/data-importing.html",
    "title": "Data importing",
    "section": "",
    "text": "The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ~ Tidyverse package docs\n\nThe tidyverse collection of packages includes:\n\nggplot2 - for data visualization\ndplyr - for data wrangling\nreadr - for reading data\ntibble - for modern data frames\nstringr: for string manipulation\nforcats: for dealing with factors\ntidyr: for data tidying\npurrr: for functional programming\n\nWe load the tidyverse like any other package, with library(tidyverse). When we do, we will receive a message with (1) a list packages that were loaded and (2) a warning that there are potential conflicts with base R’s stats functions\n\nWe can resolve conflicts with the :: operator, which allows us to specify which package our intended function belongs to as a prefix: stats::filter() or dplyr::filter()"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#welcome-to-the-tidyverse",
    "href": "lecturenotes/r/data-importing.html#welcome-to-the-tidyverse",
    "title": "Data importing",
    "section": "",
    "text": "The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. ~ Tidyverse package docs\n\nThe tidyverse collection of packages includes:\n\nggplot2 - for data visualization\ndplyr - for data wrangling\nreadr - for reading data\ntibble - for modern data frames\nstringr: for string manipulation\nforcats: for dealing with factors\ntidyr: for data tidying\npurrr: for functional programming\n\nWe load the tidyverse like any other package, with library(tidyverse). When we do, we will receive a message with (1) a list packages that were loaded and (2) a warning that there are potential conflicts with base R’s stats functions\n\nWe can resolve conflicts with the :: operator, which allows us to specify which package our intended function belongs to as a prefix: stats::filter() or dplyr::filter()"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#what-is-tidy-data",
    "href": "lecturenotes/r/data-importing.html#what-is-tidy-data",
    "title": "Data importing",
    "section": "2 What is tidy data?",
    "text": "2 What is tidy data?\nThe same underlying data can be represented in a table in many different ways; some easier to work with than others. The tidyverse makes use of tidy data principles to make datasets easier to work with in R. Tidy data provides a standard way of structuring datasets:\n\neach variable forms a column; each column forms a variable\neach observation forms a row; each row forms an observation\nvalue is a cell; each cell is a single value\n\nWhy is tidy data easier to work with?\n\nBecause consistency and uniformity are very helpful when programming\nVariables as columns works well for vectorized languages (R!)"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#functional-programming-with-purrr",
    "href": "lecturenotes/r/data-importing.html#functional-programming-with-purrr",
    "title": "Data importing",
    "section": "3 Functional programming with purrr",
    "text": "3 Functional programming with purrr\n\npurrr enhances R’s functional programming (FP) toolkit by providing a complete and consistent set of tools for working with functions and vectors. If you’ve never heard of FP before, the best place to start is the family of map() functions which allow you to replace many for loops with code that is both more succinct and easier to read. ~ purrr docs\n\nLet’s illustrate the joy of the tidyverse with one of its packages: purrr. The docs say that the best place to start is the family of map() functions, so we’ll do that.\nThe map() functions:\n\ntake a vector as input\napply a function to each element\nreturn a new vector\n\nWe say “functions” because there are 5, one for each type of vector:\n\nmap()\nmap_lgl()\nmap_int()\nmap_dbl()\nmap_chr()\n\nTo illustrate, suppose we have a data frame df with 3 columns and we want to compute the mean of each column. We could solve this with copy-and-paste (run mean() 3 different times) or try to use a for loop, but map() can do this with just one line:\nmap_dbl(df, mean)\nNow imagine we have 5 more data frames and we want to compute the mean of each of their columns, too. Again, we could copy and paste the map() function or use it in a for loop. But the map family allows us go up a layer of abstraction. We can use pmap() when we want to apply a function element-wise to corresponding items in multiple lists."
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#modern-data-frames-with-tibble",
    "href": "lecturenotes/r/data-importing.html#modern-data-frames-with-tibble",
    "title": "Data importing",
    "section": "4 Modern data frames with tibble",
    "text": "4 Modern data frames with tibble\n\nA tibble, or tbl_df, is a modern reimagining of the data.frame, keeping what time has proven to be effective, and throwing out what is not. Tibbles are data.frames that are lazy and surly: they do less and complain more ~ tibble docs\n\nTibbles do less than data frames, in a good way:\n\nnever changes type of input (never converts strings to factors!)\nnever changes the name of variables\nonly recycles vectors of length 1\nnever creates row names\n\nYou can read more in vignette(“tibble”) if you are interested, but understanding these differences is not necessary to be successful in the course. The take-away is that data.frame and tibble sometimes behave differently. The behavior of tibble makes more sense for modern data science, so we should us it instead!\nCreate a tibble with one of the following:\n# (1) coerce an existing object with\nas_tibble(x)\n\n# (2) pass a column of vectors \ntibble(x=1:5, y=1)\n\n# (3) define row-by-row, short for traansposed tibble\ntribble(\n    ~x, ~y, ~z,\n    \"a\", 2, 3.6,\n    \"b\", 1, 8.5\n)\nWe will encounter two main ways tibbles and data frames differ:\n\nprinting - by default, tibbles print the first 10 rows and all columns that fit on screen, making it easier to work with large datasets. Tibbles also report the type of each column (e.g. &lt;dbl&gt;, &lt;chr&gt;)\nsubsetting - tibbles are more strict than data frames, which fixes two quirks we encountered last lecture when subsetting with [[ and $: (1) tibbles never do partial matching, and (2) they always generate a warning if the column you are trying to extract does not exist.\n\nTo test if something is a tibble or a data.frame:\n\nis_tibble(x)\nis.data.frame(x)"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#reading-data-with-readr",
    "href": "lecturenotes/r/data-importing.html#reading-data-with-readr",
    "title": "Data importing",
    "section": "5 Reading data with readr",
    "text": "5 Reading data with readr\n\nThe goal of readr is to provide a fast and friendly way to read rectangular data from delimited files, such as comma-separated values (CSV) and tab-separated values (TSV). It is designed to parse many types of data found in the wild, while providing an informative problem report when parsing leads to unexpected results. ~ readr docs\n\nOften we want to read in some data we’ve generated or collected outside of R. The most basic and common format is plain-text rectangular files. We will “read” these into R with readr’s read_*() functions.\nThe read_*() functions have two important arguments:\n\nfile path - the path to the file (that reader will try to parse)\ncolumn specification - a description of how each column should be converted from a character vector to a specific data type (col_types)\n\nThere are 7 supported file types, each with their own read_*() function:\n\nread_csv(): comma-separated values (CSV)\nread_tsv(): tab-separated values (TSV)\nread_csv2(): semicolon-separated values\nread_delim(): delimited files (CSV and TSV are important special cases)\nread_fwf(): fixed-width files\nread_table(): whitespace-separated files\nread_log(): web log files\n\nTo read .csv files, include a path and (optionally) a column specification:\n# (1) pass only the path; readr guesses col_types \nread_csv(path='path/to/file.csv')\n\n# (2) include a column specification with col_types\nread_csv(\n    path='path/to/file.csv', \n    col_types = list( x = col_string(), y = col_skip() )\n)\nWith no colum specification, readr uses the the first 1000 rows to guess with a simple heuristic:\n\nif column contains only T/F, logical\nif only numbers, double\nif ISO8601 standard, date or date-time\notherwise string\n\nThere are 11 column types that can be specified:\n\ncol_logical() - reads as boolean TRUE FALSE values\ncol_integer() - reads as integer\ncol_double() - reads as double\ncol_number() - numeric parser that can ignore non-numbers\ncol_character() - reads as strings\ncol_factor(levels, ordered = FALSE) - creates factors\ncol_datetime(format = \"\") - creates date-times\ncol_date(format = \"\") - creates dates\ncol_time(format = \"\") - creates times\ncol_skip() - skips a column\ncol_guess() - tries to guess the column\n\nSome useful additional arguments:\n\nif there is no header, include col_names = FALSE\nto provide a header, include col_names = c(\"x\",\"y\",\"z\")\nto skip some lines, include skip = n, where n is number of lines to skip\nto select which columns to import, include col_select(x, y)\nto guess column types with all rows, include guess_max = Inf\n\nSometimes weird things happen. The most common problems are:\n\nmissing values are not NA - your dataset has missing values, but they are not coded as NA as R expects. Solve by adding na argument (e.g. na=c(\"N/A\"))\ncolumn names have spaces - R cannot include spaces in variable names, so it adds backticks (e.g. `brain size`); we can just refer to them with backticks, but if that gets annoying, see janitor::clean_names() to fix them!\n\nReading more complex file types requires functions outside the tidyverse:\n\nexcel with readxl - see Spreadsheets in R for Data Science\ngoogle sheets with googlesheets4 - see Spreadsheets in R for Data Science\ndatabases with DBI - see Databases in R for Data Science\njson data with jsonlite - see Hierarchical data in R for Data Science"
  },
  {
    "objectID": "lecturenotes/r/data-importing.html#further-reading-and-references",
    "href": "lecturenotes/r/data-importing.html#further-reading-and-references",
    "title": "Data importing",
    "section": "Further reading and references",
    "text": "Further reading and references\nRecommended further reading:\n\nData tidying in R for Data Science\nTibbles in R for Data Science\nData import in R for Data Science:\nreadr cheatsheet"
  },
  {
    "objectID": "lecturenotes/r/data-visualization.html",
    "href": "lecturenotes/r/data-visualization.html",
    "title": "Data visualization",
    "section": "",
    "text": "test"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html",
    "href": "lecturenotes/r/r-basics.html",
    "title": "R Basics",
    "section": "",
    "text": "Defining some basic concepts:\n\nExpressions are combination of values, variables, operators, and functions that can be evaluated to produce a result. Expressions can be as simple as a single value or more complex involving calculations, comparisons, and function calls. They are the fundamental building blocks of programming.\n\n10 - a simple value expression that evaluates to 10.\nx + 10 - an expression that adds the value of x to 10\na &lt;- x + 10 - an expression that adds the value of x to 10 and assigns the result to the variable a\n\nObjects in R allow us to store various types of data, such as numbers, text, vectors, matrices; and more complex structures like functions and data frames. Objects are created by assigning values to variable names with the assignment operator, &lt;-. For example, in x &lt;- 10, x is an object assigned to the value 10.\nNames that we assign to objects must include only letters, numbers, ., or _. Names must start with a letter (or . if not followed by a number).\nAttributes allow you to attach arbirary metadata to an object. For example, adding a dim (dimension) attribute to a vector allows it to behave like a matrix or n dimensional array.\nFunctions (or commands) are reusable pieces of code that take some input, preform some task or computation, and return an output. Many functions are built-in to base R (see below!), others can be part of packages or even defined by you. Functions are objects!\nEnvironment is the collection of all the objects (functions, variables etc.) we defined in the current R session.\nPackages are collections of functions, data, and documentation bundled together in R. They enhance R’s capabilities by introducing new functions and specialized data structures. Packages need to be installed and loaded before you can use their functions or data.\nComments are notes you leave to yourself (within code blocks in colab) to document your code; comments are not evaluated.\nMessages are notes R leaves for you, after you run your code. Messages can be simply for-your-information, warnings that something unexpected might happen, or erros if R cannot evaluate your code.\n\nWays to get help when coding in R:\n\nRead packages docs - packages usually come with extensive documentation and examples. Reading the docs is one of the best ways to figure things out. Here is an example from the dplyr package.\nRead error messages - read any error messages you receive while coding — they give clues about what is going wrong!\nAsk R - Use R’s built-in functions to get help as you code\nAsk on Ed- ask questions on our class discussion board!\nAsk Google/Stack Overflow - It is a normal and important skill (not cheating) to google things while coding and learning to code! Use keywords and package names to ensure your solutions are course-relevant.\nAsk ChatGPT - You can similarly use ChatGPT or other LLMs as a resource. But keep in mind they may provide a solution that is wrong or not relevant to what we are learning in this course."
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#basics",
    "href": "lecturenotes/r/r-basics.html#basics",
    "title": "R Basics",
    "section": "",
    "text": "Defining some basic concepts:\n\nExpressions are combination of values, variables, operators, and functions that can be evaluated to produce a result. Expressions can be as simple as a single value or more complex involving calculations, comparisons, and function calls. They are the fundamental building blocks of programming.\n\n10 - a simple value expression that evaluates to 10.\nx + 10 - an expression that adds the value of x to 10\na &lt;- x + 10 - an expression that adds the value of x to 10 and assigns the result to the variable a\n\nObjects in R allow us to store various types of data, such as numbers, text, vectors, matrices; and more complex structures like functions and data frames. Objects are created by assigning values to variable names with the assignment operator, &lt;-. For example, in x &lt;- 10, x is an object assigned to the value 10.\nNames that we assign to objects must include only letters, numbers, ., or _. Names must start with a letter (or . if not followed by a number).\nAttributes allow you to attach arbirary metadata to an object. For example, adding a dim (dimension) attribute to a vector allows it to behave like a matrix or n dimensional array.\nFunctions (or commands) are reusable pieces of code that take some input, preform some task or computation, and return an output. Many functions are built-in to base R (see below!), others can be part of packages or even defined by you. Functions are objects!\nEnvironment is the collection of all the objects (functions, variables etc.) we defined in the current R session.\nPackages are collections of functions, data, and documentation bundled together in R. They enhance R’s capabilities by introducing new functions and specialized data structures. Packages need to be installed and loaded before you can use their functions or data.\nComments are notes you leave to yourself (within code blocks in colab) to document your code; comments are not evaluated.\nMessages are notes R leaves for you, after you run your code. Messages can be simply for-your-information, warnings that something unexpected might happen, or erros if R cannot evaluate your code.\n\nWays to get help when coding in R:\n\nRead packages docs - packages usually come with extensive documentation and examples. Reading the docs is one of the best ways to figure things out. Here is an example from the dplyr package.\nRead error messages - read any error messages you receive while coding — they give clues about what is going wrong!\nAsk R - Use R’s built-in functions to get help as you code\nAsk on Ed- ask questions on our class discussion board!\nAsk Google/Stack Overflow - It is a normal and important skill (not cheating) to google things while coding and learning to code! Use keywords and package names to ensure your solutions are course-relevant.\nAsk ChatGPT - You can similarly use ChatGPT or other LLMs as a resource. But keep in mind they may provide a solution that is wrong or not relevant to what we are learning in this course."
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#important-functions",
    "href": "lecturenotes/r/r-basics.html#important-functions",
    "title": "R Basics",
    "section": "Important functions",
    "text": "Important functions\nFor objects:\n\nstr(x) - returns summary of object’s structure\ntypeof(x) - returns object’s data type\nlength(x) - returns object’s length\nattributes(x) - returns list of object’s attributes\nis.*(x) - test if object is data type (e.g. is.double(x))\nas.*(x) - coerce object to data type (e.g. as.double(x))\n\nfor environment:\n\nls() - list all variables in environment\nrm(x) - remove x variable from environment\nrm(list = ls()) - remove all variables from environment\n\nFor packages:\n\ninstall.packages() to install packages\nlibrary() to load the package into your current R session.\ndata() to load data from package into environment\nsessionInfo() - version information for current R session and packages\n\nFor help:\n\n?mean - get help with a function\nhelp.search('mean') - search help files for word or phrase\nhelp(package='tidyverse') - find help for a package"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#vectors",
    "href": "lecturenotes/r/r-basics.html#vectors",
    "title": "R Basics",
    "section": "Vectors",
    "text": "Vectors\nOne of the must fundamental data structures in R is the vector. There are two types:\n\natomic vector - elements of the same data type\nlist - elements refer to any object (even complex objects or other lists)\n\nAtomic vectors can be one of six data types:\n\ndouble - real numbers, written in decimal (0.1234) or scientific notation (1.23e4)\n\nnumbers are double by default (3 is stored as 3.00)\nthree special doubles: Inf, -Inf, and NaN (not a number)\n\ninteger - integers, numbers followed by L (3L or 1e3L)\ncharacter - strings with single or double quotes (‘hello world!’ or “hello world!”)\nlogical - boolean written (TRUE or FALSE) or abbreviated (T or F)\ncomplex - complex numbers where i is imaginary (5 + 3i)\nraw - stores raw bytes\n\nSome more complex data structures are built from atomic vectors by adding attributes:\n\nmatrix - a vector with a dim attribute representing 2 dimensions\narray - a vector with a dim attribute representing n dimensions\nfactor - an integer vector with two attributes: class=\"factor\" and levels, which defines the set of allowed values (useful for categorical data)\ndate-time - a double vector where the value is the number of seconds since Jan 01, 1970 and a tzone attribute representing the time zone\ndata.frame - a named list of vectors (of equal length) with attributes for names (column names), row.names, and class=\"data.frame\" (used to represent datasets)\n\nTo create atomic vectors:\n\nc(2,4,6) - c for combine, returns 2 4 6\n2:4 - vector of integers, returns 2 3 4\nseq(2:6, by=2) - sequence by, returns 2 4 6\n\nTo create more complex structures:\n\nlist(x=c(1,2,3), y=c('a','b')) - create a list\nmatrix(x, nrow=2, ncol=2) - create a matrix from x with nrow and ncol\narray(x, dim=c(2,3,2)) - create an array from x with dimensions\nfactor(x, levels=unique(x)) - turn a vector into a factor\ndata.frame(x=c(1,2,3), y=c('a','b','c')) - create a data frame\n\nMissing elements and empty vectors:\n\nNA- used to represent missing or unknown elements in vectors. Note that NA is contageous: expressions including NA usually return NA\nNULL - used to represent an empty or absent vector of arbitrary type. NULL is its own special type and always has length zero and NULL attributes."
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#subsetting",
    "href": "lecturenotes/r/r-basics.html#subsetting",
    "title": "R Basics",
    "section": "Subsetting",
    "text": "Subsetting\n\nSubsetting is a natural complement to str(). While str() shows you all the pieces of any object (its structure), subsetting allows you to pull out the pieces that you’re interested in. ~ Hadley Wickham, Advanced R\n\nThere are three operators for subsetting objects:\n\n[ - selects multiple elements\n[[ and $ - extracts a single element\n\nThere are six ways to select multiple elements from vectors with [:\n\nx[c(1,2)] - positive integers select elements at specified indexes\nx[-c(1,2)] - negative integers select all but elements at specified indexes\nx[c(\"name\", \"name2\")] select elements by name, if elements are named\nx[] - nothing returns the original object\nx[0] - zero returns a zero-length vector\nx[c(TRUE, TRUE)] - select elements where corresponding logical value is TRUE\n\nThese also apply when selecting multiple elements from higher dimensional objects (matrix, array, data frame), but note that:\n\nindexes for different dimensions are separated by commas [rows, columns, ...]\nomitted dimensions return all values along that dimension\nthe result is simplified to the lowest possible dimensions by default\nthey can also be indexed like a vector (selects columns)\n\nThere are 3 ways to extract a single element from any data structure:\n\n[[2]] - a single positive integer (index)\n[['name']] - a single string\nx$name - the $ operator is a useful shorthand for [['name']]\n\nWhen extracting single elements, note that:\n\n[[ is preferred for atomic vectors for clarity (though[ also works)\n$ does partial matching without warning; use options(warnPartialMatchDollar=TRUE)\nthe behavior for invalid indexes is inconsistent: sometimes you’ll get an error message, and sometimes it will return NULL"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#operations",
    "href": "lecturenotes/r/r-basics.html#operations",
    "title": "R Basics",
    "section": "Operations",
    "text": "Operations\nArithmetic operators:\n\n+ - add\n- - subtract\n* - multiply\n/ - divide\n^ - exponent\n\nComparison operators return true or false:\n\na == b - equal to\na != b - not equal to\na &gt; b - greater than\na &lt; b - less than\na &gt;= b - greater than or equal to\na &lt;= b - less than or equal to\n\nLogical operators combine multiple true or false statements:\n\n& - and\n| - or\n! - not\nany() - returns true if any element meets condition\nall() - returns true if all elements meet condition\n%in% - returns true if any element is in the following vector\n\nMost math operations (and many functions) are vectorized in R:\n\nthey can work on entire vectors, without the need for explicit loops or iteration.\nthis a powerful feature that allows you to write cleaner, more efficient code\nTo illustrate, suppose x &lt;- c(1, 2, 3):\n\nx + 100 returns [101 102 103]\nx == 1 returns [TRUE FALSE FALSE]"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#built-in-functions",
    "href": "lecturenotes/r/r-basics.html#built-in-functions",
    "title": "R Basics",
    "section": "Built-in functions",
    "text": "Built-in functions\nNote that you do not need to memorize these built-in functions to be successful on quizzes. Use this as a reference.\nFor basic math:\n\nlog(x) - natural log\nexp(x) - exponential\nsqrt(x) - square root\nabs(x) - absolute value\nmax(x) - largest element\nmin(x) - smallest element\nround(x, n) - round to n decimal places\nsignif(x, n) - round to n significant figures\nsum(x) - add all elements\n\nFor stats:\n\nmean(x) - mean\nmedian(x) - median\nsd(x) - standard deviation\nvar(x) - variance\nquantile(x) - percentage quantiles\nrank(x) - rank of elements\ncor(x, y) - correlation\nlm(x ~ y, data=df) - fit a linear model\nglm(x ~ y, data=df) - fit a generalized linear model\nsummary(x) - get more detailed information from a fitted model\naov(x) - analysis of variance\n\nFor vectors:\n\nsort(x) - return sorted vector\ntable(x) - see counts of values in a vector\nrev(x) - return reversed vector\nunique(x) - return unique values in a vector\ndim(x) - transform vector into n-dimensional array\n\nFor matrices:\n\nt(m) - transpose matrix\nm %+% n - matrix multiplication\nsolve(m, n) - find x in m * x = n\n\nFor data frames:\n\nview(df) - see the full data frame\nhead(df) - see the first 6 rows of data frame\nnrow(df) - number of rows in a data frame\nncol(df) - number of columns in a data frame\ndim(df) - number of columns and rows in a data frame\ncbind(df1, df2) - bind columns\nrbind(df1, df2) - bind rows\n\nFor strings:\n\npaste(x, y, sep=' ') - join multiple vectors together\ntoupper(x) - convert to uppercase\ntolower(x) - convert to lowercase\nnchar(x) - number of characters in a string\n\nFor simple plotting:\n\nplot(x) values of x in order\nplot(x, y) - values of x against y\nhist(x) - histogram of x"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#programming-in-r",
    "href": "lecturenotes/r/r-basics.html#programming-in-r",
    "title": "R Basics",
    "section": "Programming in R",
    "text": "Programming in R\nWriting functions and handling flow control are important aspects of learning to program in any language. For our purposes, some general conceptual knowledge on these topics is sufficient (see below). Those interested to learn more might enjoy the book Hands-On Programming with R.\n\nFunctions are reusable pieces of code that take some input, perform some task or computation, and return an output.\nfunction(inputs){\n    # do something\n    return(output)\n}\nFlow control refers to managing the order in which expressions are executed in a program:\n\nif…else - if something is true, do this; otherwise do that\nfor loops - repeat code a specific number of times\nwhile loops - repeat code as long as certain conditions are true\nbreak - exit a loop early\nnext - skip to next iteration in a loop"
  },
  {
    "objectID": "lecturenotes/r/r-basics.html#further-reading-and-references",
    "href": "lecturenotes/r/r-basics.html#further-reading-and-references",
    "title": "R Basics",
    "section": "Further reading and references",
    "text": "Further reading and references\nSuggested further reading:\n\nBase R Cheat Sheet\nGetting Started with Data in R in ModernDive textbook\nR Nuts and Bolts in R Programming for Data Science by Roger Peng\n\nOther references:\n\nMatlab vs. Julia vs. Python from blog post by Toby Driscoll\nVectors in Advanced R by Hadley Wickham\nSubsetting in Advanced R by Hadley Wickham\nA field guide to base R in R for Data Science by Hadley Wickham"
  },
  {
    "objectID": "rubric.html",
    "href": "rubric.html",
    "title": "Rubric",
    "section": "",
    "text": "All quiz and problem set questions are graded with the following 4-point rubric. By “understand” we mean you understand the lecture concepts and can apply the technical skills you learned in the course."
  },
  {
    "objectID": "rubric.html#overall-grade",
    "href": "rubric.html#overall-grade",
    "title": "Rubric",
    "section": "Overall grade",
    "text": "Overall grade\nTo compute your overall grade on a problem set or quiz, we take your average score on all questions, add a constant of 6, and divide by 10. For example, given a problem set with 3 questions:\n\nscores of 4-3-3 would result in a 93.3% (A): (4+3+3)/3 + 6 = 9.33/10\nscores of 3-2-2 would result in a 83.3% (B-): (3+2+2)/3 + 6 = 8.33/10\nscores of 1-1-1 would result in a 70% (C-): (1+1+1)/3 + 6 = 7/10\n\nWe chose this rubric because all reasonable attempts receive a passing grade, but A+ is reserved for students with advanced understanding of the material."
  },
  {
    "objectID": "rubric.html#missing-or-blank-work",
    "href": "rubric.html#missing-or-blank-work",
    "title": "Rubric",
    "section": "Missing or blank work",
    "text": "Missing or blank work\nProblem sets or quizzes that are completely missing or blank will receive a 0%."
  }
]